{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0feb559b-6f32-438a-9d36-88a563e789f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import sys\n",
    "from imp import reload\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "if sys.version[0] == '2':\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding(\"utf-8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a82a2b4-1f92-4f21-b201-438f789d8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "   sentiment                                             review\n",
      "0          1  With all this stuff going down at the moment w...\n",
      "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2          0  The film starts with a manager (Nicholas Bell)...\n",
      "3          0  It must be assumed that those who praised this...\n",
      "4          1  Superbly trashy and wondrously unpretentious 8...\n",
      "(50000, 2)\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('../kaggleDatasets/BagofWordsMeetsBagsofPopcorn/labeledTrainData.tsv', delimiter=\"\\t\")\n",
    "df1 = df1.drop(['id'], axis=1)\n",
    "print(df1.shape)\n",
    "print(df1.head())\n",
    "\n",
    "df2 = pd.read_csv('../kaggleDatasets/BagofWordsMeetsBagsofPopcorn/IMDB_Dataset.csv',encoding=\"latin-1\")\n",
    "print(df2.shape)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7845e38a-7a3d-419f-a0fc-9a4e31408591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  One of the other reviewers has mentioned that ...          1\n",
      "1  A wonderful little production. <br /><br />The...          1\n",
      "2  I thought this was a wonderful way to spend ti...          1\n",
      "3  Basically there's a family where a little boy ...          0\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...          1\n"
     ]
    }
   ],
   "source": [
    "df2 = df2[df2.sentiment != 'unsup']\n",
    "df2['sentiment'] = df2['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f0b519f-a90f-409a-bbfd-39b04d63de02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  With all this stuff going down at the moment w...\n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2          0  The film starts with a manager (Nicholas Bell)...\n",
       "3          0  It must be assumed that those who praised this...\n",
       "4          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9ad579b-f917-48a3-aaf7-307980b64a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "  \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\")) \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6e6cea5-102a-4e8b-a32e-f066ffd10e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)   ## Replaces special character\n",
    "    text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    text = [word for word in text if not word in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "df['Processed_Reviews'] = df.review.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de46b2db-4c77-4efa-8c20-84720250009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>Processed_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>stuff go moment mj ive start listen music watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>classic war world timothy hines entertain film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>film start manager nicholas bell give welcome ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>must assume praise film greatest film opera ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbly trashy wondrously unpretentious 80 ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review  \\\n",
       "0          1  With all this stuff going down at the moment w...   \n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2          0  The film starts with a manager (Nicholas Bell)...   \n",
       "3          0  It must be assumed that those who praised this...   \n",
       "4          1  Superbly trashy and wondrously unpretentious 8...   \n",
       "\n",
       "                                   Processed_Reviews  \n",
       "0  stuff go moment mj ive start listen music watc...  \n",
       "1  classic war world timothy hines entertain film...  \n",
       "2  film start manager nicholas bell give welcome ...  \n",
       "3  must assume praise film greatest film opera ev...  \n",
       "4  superbly trashy wondrously unpretentious 80 ex...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3581321d-3f3c-467d-8031-962ecd21cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c282c92-9e3b-4caa-bde9-07061560eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "600/600 [==============================] - 50s 80ms/step - loss: 0.3286 - accuracy: 0.8584 - val_loss: 0.2573 - val_accuracy: 0.8941\n",
      "Epoch 2/3\n",
      "600/600 [==============================] - 52s 86ms/step - loss: 0.2048 - accuracy: 0.9210 - val_loss: 0.2524 - val_accuracy: 0.9039\n",
      "Epoch 3/3\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 0.1579 - accuracy: 0.9428 - val_loss: 0.2331 - val_accuracy: 0.9120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3e06ffe80>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(df['Processed_Reviews'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(df['Processed_Reviews'])\n",
    "\n",
    "maxlen = 130\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "y = df['sentiment']\n",
    "\n",
    "embed_size = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_size))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 3\n",
    "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85e9d430-60f4-4475-8fee-37e173be1a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                             review\n",
      "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
      "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
      "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
      "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
      "4   \"12128_7\"  \"A very accurate depiction of small time mob l...\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv(\"../kaggleDatasets/BagofWordsMeetsBagsofPopcorn/testData.tsv\",header=0, delimiter=\"\\t\", quoting=3)\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d04f649-4469-44ea-a8ef-69e1163a6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"review\"]=df_test.review.apply(lambda x: clean_text(x))\n",
    "df_test[\"sentiment\"] = df_test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)\n",
    "y_test = df_test[\"sentiment\"]\n",
    "list_sentences_test = df_test[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e2450c0-7a3c-4e02-a81e-739b7996cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "prediction = model.predict(X_te)\n",
    "y_pred = (prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c836a0b-fad2-42d5-b605-00344fdfd995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.9287103046014259\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11776,  1036],\n",
       "       [  724, 11464]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "print('F1-score: {0}'.format(f1_score(y_pred, y_test)))\n",
    "print('Confusion matrix:')\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1dd70-18a0-45a9-861f-320c802a7af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universal",
   "language": "python",
   "name": "universal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
